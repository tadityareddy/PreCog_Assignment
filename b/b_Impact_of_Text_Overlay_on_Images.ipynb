{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr ultralytics"
      ],
      "metadata": {
        "id": "cNbzlRgk2mQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "yEhau7A12xBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])"
      ],
      "metadata": {
        "id": "lwI06h7W3Ef1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the YOLO model\n",
        "detectionmodel = YOLO('yolov8n.pt')"
      ],
      "metadata": {
        "id": "lreg9JYhUVxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text_from_image(image_path):\n",
        "    \"\"\"\n",
        "    Takes an image path and returns the text detected in the image.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "\n",
        "    Returns:\n",
        "        str: The detected text in the image.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    output = reader.readtext(image)\n",
        "    result = \"\"\n",
        "    for i in range(len(output)):\n",
        "        result += output[i][1] + \" \"\n",
        "    return result\n",
        "\n",
        "def get_text_coordinates(image_path):\n",
        "    \"\"\"\n",
        "    Takes an image path and returns the coordinates of the detected text.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of lists, where each inner list represents the coordinates of a detected text box.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    output = reader.readtext(image)\n",
        "    result = []\n",
        "    for i in range(len(output)):\n",
        "        result.append(output[i][0])\n",
        "    return result\n",
        "\n",
        "def get_object_coordinates(image_path):\n",
        "    \"\"\"\n",
        "    Takes an image path and returns the coordinates of the detected objects.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of lists, where each inner list represents the coordinates of a detected object.\n",
        "    \"\"\"\n",
        "    detection_results = detectionmodel(image_path, save=True)\n",
        "    detection_boxes = detection_results[0].boxes\n",
        "    classes = detection_results[0].boxes.cls.cpu().numpy()\n",
        "    detectionnames = detection_results[0].names\n",
        "    res = detection_boxes.cls.cpu().numpy().tolist()\n",
        "    cls = []\n",
        "    for i in res:\n",
        "        cls.append(detectionnames[i])\n",
        "    conf = detection_results[0].boxes.conf.cpu().numpy()\n",
        "    xyxy = detection_results[0].boxes.xyxy.cpu().numpy()\n",
        "    obj_boxes = []\n",
        "    for i in range(len(classes)):\n",
        "        if conf[i] > 0.5:\n",
        "            x_min = int(xyxy[i][0])\n",
        "            y_min = int(xyxy[i][1])\n",
        "            x_max = int(xyxy[i][2])\n",
        "            y_max = int(xyxy[i][3])\n",
        "            obj_boxes.append([[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]])\n",
        "\n",
        "    return obj_boxes,cls\n",
        "\n",
        "def calculate_area(box):\n",
        "    \"\"\"\n",
        "    Calculates the area of a bounding box.\n",
        "\n",
        "    Args:\n",
        "        box (list): A list of four coordinates representing the bounding box.\n",
        "\n",
        "    Returns:\n",
        "        float: The area of the bounding box.\n",
        "    \"\"\"\n",
        "    x = [point[0] for point in box]\n",
        "    y = [point[1] for point in box]\n",
        "    return 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n",
        "\n",
        "def calculate_percentage(area, total_area):\n",
        "    \"\"\"\n",
        "    Calculates the percentage of an area relative to a total area.\n",
        "\n",
        "    Args:\n",
        "        area (float): The area to calculate the percentage for.\n",
        "        total_area (float): The total area.\n",
        "\n",
        "    Returns:\n",
        "        float: The percentage of the area relative to the total area.\n",
        "    \"\"\"\n",
        "    return (area / total_area) * 100\n",
        "\n",
        "def calculate_text_percentage(image_path):\n",
        "    \"\"\"\n",
        "    Calculates the percentage of the image area covered by the detected text.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "\n",
        "    Returns:\n",
        "        float: The percentage of the image area covered by the detected text.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    total_image_area = image.shape[0] * image.shape[1]\n",
        "\n",
        "    boxes = get_text_coordinates(image_path)\n",
        "    total_boxes_area = 0\n",
        "    for box in boxes:\n",
        "        box_area = calculate_area(box)\n",
        "        total_boxes_area += box_area\n",
        "\n",
        "    text_percentage = calculate_percentage(total_boxes_area, total_image_area)\n",
        "    return text_percentage\n",
        "\n",
        "def calculate_object_percentage(image_path):\n",
        "    \"\"\"\n",
        "    Calculates the percentage of the image area covered by the detected objects.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "\n",
        "    Returns:\n",
        "        float: The percentage of the image area covered by the detected objects.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    total_image_area = image.shape[0] * image.shape[1]\n",
        "\n",
        "    obj_boxes, classes = get_object_coordinates(image_path)\n",
        "    total_boxes_area = 0\n",
        "    for box in obj_boxes:\n",
        "        box_coords = box\n",
        "        box_area = calculate_area(box_coords)\n",
        "        total_boxes_area += box_area\n",
        "\n",
        "    object_percentage = calculate_percentage(total_boxes_area, total_image_area)\n",
        "    return object_percentage\n",
        "\n",
        "def calculate_intersection_area(box_a, box_b):\n",
        "    \"\"\"Calculates the intersection area between two bounding boxes.\n",
        "\n",
        "    Args:\n",
        "    box_a (list of lists): The coordinates of the first bounding box.\n",
        "    box_b (list of lists): The coordinates of the second bounding box.\n",
        "\n",
        "    Returns:\n",
        "    float: The intersection area between the two bounding boxes.\n",
        "    \"\"\"\n",
        "    # Extract coordinates of box_a\n",
        "    x_min_a = min(coord[0] for coord in box_a)\n",
        "    y_min_a = min(coord[1] for coord in box_a)\n",
        "    x_max_a = max(coord[0] for coord in box_a)\n",
        "    y_max_a = max(coord[1] for coord in box_a)\n",
        "\n",
        "    # Extract coordinates of box_b\n",
        "    x_min_b = min(coord[0] for coord in box_b)\n",
        "    y_min_b = min(coord[1] for coord in box_b)\n",
        "    x_max_b = max(coord[0] for coord in box_b)\n",
        "    y_max_b = max(coord[1] for coord in box_b)\n",
        "\n",
        "    # Calculate intersection coordinates\n",
        "    x_min_i = max(x_min_a, x_min_b)\n",
        "    y_min_i = max(y_min_a, y_min_b)\n",
        "    x_max_i = min(x_max_a, x_max_b)\n",
        "    y_max_i = min(y_max_a, y_max_b)\n",
        "\n",
        "    # Calculate intersection area\n",
        "    intersection_width = max(0, x_max_i - x_min_i + 1)\n",
        "    intersection_height = max(0, y_max_i - y_min_i + 1)\n",
        "    intersection_area = intersection_width * intersection_height\n",
        "\n",
        "    return intersection_area\n",
        "\n",
        "\n",
        "def calculate_intersection_percentage(image_path):\n",
        "    \"\"\"\n",
        "    Calculates the percentage of the image area covered by the intersection between detected text and objects.\n",
        "\n",
        "    Args:\n",
        "        image_path (str): Path to the input image.\n",
        "\n",
        "    Returns:\n",
        "        float: The percentage of the image area covered by the intersection between detected text and objects.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    total_image_area = image.shape[0] * image.shape[1]\n",
        "\n",
        "    text_boxes = get_text_coordinates(image_path)\n",
        "    obj_boxes, classes = get_object_coordinates(image_path)\n",
        "\n",
        "    total_intersection_area = 0\n",
        "    for text_box in text_boxes:\n",
        "        for obj_box in obj_boxes:\n",
        "\n",
        "            intersection_area = calculate_intersection_area(text_box, obj_box)\n",
        "            total_intersection_area += intersection_area\n",
        "\n",
        "    intersection_percentage = calculate_percentage(total_intersection_area, total_image_area)\n",
        "    return intersection_percentage"
      ],
      "metadata": {
        "id": "WpGwx2xx6MFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"01278.png\""
      ],
      "metadata": {
        "id": "ae-sw6MN-DVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage of read_text_from_image function\n",
        "text_detected = read_text_from_image(image_path)\n",
        "\n",
        "# Example usage of get_text_coordinates function\n",
        "text_coordinates = get_text_coordinates(image_path)\n",
        "\n",
        "# Example usage of get_object_coordinates function\n",
        "object_coordinates, classes = get_object_coordinates(image_path)\n",
        "\n",
        "# Example usage of calculate_text_percentage function\n",
        "text_percentage = calculate_text_percentage(image_path)\n",
        "\n",
        "# Example usage of calculate_object_percentage function\n",
        "object_percentage = calculate_object_percentage(image_path)\n",
        "\n",
        "# Example usage of calculate_intersection_percentage function\n",
        "intersection_percentage = calculate_intersection_percentage(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Cy8mIw06M6r",
        "outputId": "8d2d025f-8577-4229-960b-44d634798385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/01278.png: 640x320 1 person, 1 tennis racket, 148.1ms\n",
            "Speed: 4.5ms preprocess, 148.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "person\n",
            "tennis racket\n",
            "\n",
            "image 1/1 /content/01278.png: 640x320 1 person, 1 tennis racket, 122.5ms\n",
            "Speed: 3.1ms preprocess, 122.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 320)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "person\n",
            "tennis racket\n",
            "\n",
            "image 1/1 /content/01278.png: 640x320 1 person, 1 tennis racket, 393.3ms\n",
            "Speed: 3.1ms preprocess, 393.3ms inference, 13.7ms postprocess per image at shape (1, 3, 640, 320)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "person\n",
            "tennis racket\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Detected Text:\", text_detected)\n",
        "print(\"Text Coordinates:\", text_coordinates)\n",
        "print(\"Object Detected:\", classes)\n",
        "print(\"Object Coordinates:\", object_coordinates)\n",
        "print(\"Text Percentage:\", text_percentage)\n",
        "print(\"Object Percentage:\", object_percentage)\n",
        "print(\"Intersection Percentage:\", intersection_percentage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LPNwQ6yVv3e",
        "outputId": "7ef58b18-8c40-4cef-a410-a056f3b5a79d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected Text: hope on a rope 1 ilsHhaleezueshbbl waiting for \n",
            "Text Coordinates: [[[60, 0], [429, 0], [429, 59], [60, 59]], [[345, 361], [359, 361], [359, 387], [345, 387]], [[33, 345], [479, 345], [479, 455], [33, 455]], [[77, 979], [406, 979], [406, 1060], [77, 1060]]]\n",
            "Object Detected: ['person', 'tennis racket']\n",
            "Object Coordinates: [[[60, 1], [511, 1], [511, 332], [60, 332]]]\n",
            "Text Percentage: 17.776889534883722\n",
            "Object Percentage: 27.122274709302324\n",
            "Intersection Percentage: 3.966206395348837\n"
          ]
        }
      ]
    }
  ]
}