{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow"
      ],
      "metadata": {
        "id": "2WC22CoIwIIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy"
      ],
      "metadata": {
        "id": "Z8whKK_-wJg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q matplotlib"
      ],
      "metadata": {
        "id": "mIwWKWBSwKTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "metadata": {
        "id": "plFCtjYRwLkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from keras.utils import load_img, img_to_array"
      ],
      "metadata": {
        "id": "VSj1eHZ0DohO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mx8m6r0KDmBw"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data():\n",
        "    \"\"\"\n",
        "    Loads and preprocesses the image data for training and validation.\n",
        "    \"\"\"\n",
        "    source_folder = \"hateful_memes/img\"\n",
        "    train_folder = \"train_data\"\n",
        "    validation_folder = \"validation_data\"\n",
        "\n",
        "    train_dir = os.path.join(source_folder, train_folder)\n",
        "    validation_dir = os.path.join(source_folder, validation_folder)\n",
        "\n",
        "    train_hateful_memes_dir = os.path.join(train_dir, 'hateful_memes')\n",
        "    train_not_hateful_memes_dir = os.path.join(train_dir, 'not_hateful_memes')\n",
        "    validation_hateful_memes_dir = os.path.join(validation_dir, 'hateful_memes')\n",
        "    validation_not_hateful_memes_dir = os.path.join(validation_dir, 'not_hateful_memes')\n",
        "\n",
        "    print('total training hateful images:', len(os.listdir(train_hateful_memes_dir)))\n",
        "    print('total training not hateful images:', len(os.listdir(train_not_hateful_memes_dir)))\n",
        "    print('total validation hateful images:', len(os.listdir(validation_hateful_memes_dir)))\n",
        "    print('total validation not hateful images:', len(os.listdir(validation_not_hateful_memes_dir)))\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255.,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "    validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        classes=['hateful_memes', 'not_hateful_memes'],\n",
        "        target_size=(224, 224),\n",
        "        batch_size=10,\n",
        "        class_mode='binary'\n",
        "    )\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        classes=['hateful_memes', 'not_hateful_memes'],\n",
        "        target_size=(224, 224),\n",
        "        batch_size=10,\n",
        "        class_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "    return train_generator, validation_generator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_and_compile_model(base_model):\n",
        "    \"\"\"\n",
        "    Builds and compiles the model.\n",
        "    \"\"\"\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = layers.Flatten()(base_model.output)\n",
        "    x = layers.Dense(512, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(base_model.input, x)\n",
        "    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['acc'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "Uy1pcU0MDrpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_generator, validation_generator):\n",
        "    \"\"\"\n",
        "    Trains the model.\n",
        "    \"\"\"\n",
        "    vgghist = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=480,\n",
        "        epochs=10,\n",
        "        verbose=1,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=120\n",
        "    )\n",
        "    return vgghist"
      ],
      "metadata": {
        "id": "PzqKGTW4Dtme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, validation_generator):\n",
        "    \"\"\"\n",
        "    Evaluates the model on validation data.\n",
        "    \"\"\"\n",
        "    val_loss, val_acc = model.evaluate(validation_generator)\n",
        "    print(\"Validation Loss:\", val_loss)\n",
        "    print(\"Validation Accuracy:\", val_acc)"
      ],
      "metadata": {
        "id": "F-Ix4dnvDvL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, filename):\n",
        "    \"\"\"\n",
        "    Saves the model.\n",
        "    \"\"\"\n",
        "    model.save(filename)"
      ],
      "metadata": {
        "id": "7lC_ECwxDw0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_images(model, image_directory):\n",
        "    \"\"\"\n",
        "    Predicts classes of images in a directory.\n",
        "    \"\"\"\n",
        "    image_files = [f for f in os.listdir(image_directory) if os.path.isfile(os.path.join(image_directory, f))]\n",
        "\n",
        "    for fn in image_files:\n",
        "        path = os.path.join(image_directory, fn)\n",
        "        img = load_img(path, target_size=(224, 224))\n",
        "        x = img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        images = np.vstack([x])\n",
        "        classes = model.predict(images, batch_size=1)\n",
        "        if classes[0] < 0.5:\n",
        "            print(fn + \" is a Hateful Meme\")\n",
        "        else:\n",
        "            print(fn + \" is a Not Hateful Meme\")\n",
        "\n",
        "def plot_training_history(vgghist):\n",
        "    \"\"\"\n",
        "    Plots training and validation accuracy and loss.\n",
        "    \"\"\"\n",
        "    plt.plot(vgghist.history['acc'])\n",
        "    plt.plot(vgghist.history['val_acc'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(vgghist.history['loss'])\n",
        "    plt.plot(vgghist.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# Load and preprocess data\n",
        "train_generator, validation_generator = load_and_preprocess_data()\n",
        "\n",
        "# Build and compile the model\n",
        "base_model = VGG16(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "model = build_and_compile_model(base_model)\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "vgghist = train_model(model, train_generator, validation_generator)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, validation_generator)\n",
        "\n",
        "# Save the model\n",
        "save_model(model, 'Classification_VGG16.keras')\n",
        "\n",
        "# Predict classes of images in a directory\n",
        "local_image_directory = \"C:\\\\Users\\\\chira\\\\Documents\\\\Projts\\\\Analysis Hateful Memes\\\\test\"\n",
        "predict_images(model, local_image_directory)\n",
        "\n",
        "# Plot training history\n",
        "plot_training_history(vgghist)"
      ],
      "metadata": {
        "id": "-o24sHWADyqs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}